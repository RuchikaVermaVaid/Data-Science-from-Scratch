{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6\n",
      "36\n",
      "[-12, -24, -36]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "####################################################################################################\n",
    "##########################            Supporting functions                ##########################\n",
    "####################################################################################################\n",
    "\"\"\"\n",
    "from Vector_operations_on_data import dot, Vector;\n",
    "\n",
    "# X: List of vectors [1,XX1,XX2,XX3]\n",
    "# y_hat  = alpha*1+beta1*XX1+beta2*XX2+....\n",
    "def predict(x:Vector, beta: Vector)-> float:\n",
    "    \"Assumes that first element of x is 1 (to add bias coefficient)\"\n",
    "    return dot(x,beta)\n",
    "\n",
    "# Assumptions: all features are independent and uncorrelated\n",
    "\n",
    "from typing import List\n",
    "def error(x:Vector, y:float, beta:Vector) -> float:\n",
    "    return predict(x,beta)-y\n",
    "\n",
    "def squared_error(x:Vector,y:float,beta:Vector)-> float:\n",
    "    return error(x,y,beta)**2\n",
    "\n",
    "def sqerror_gradient(x:Vector,y:float,beta:Vector) -> Vector:\n",
    "    err = error(x,y,beta)\n",
    "    return [2*err*x_i for x_i in x]\n",
    "\n",
    "\n",
    "x=[1,2,3]\n",
    "y = 30\n",
    "beta = [4,4,4]\n",
    "print(error(x,y,beta))\n",
    "print(squared_error(x,y,beta)) \n",
    "print(sqerror_gradient(x,y,beta))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "####################################################################################################\n",
    "##########################         Define least square fit function       ##########################\n",
    "####################################################################################################\n",
    "\"\"\"\n",
    "import random\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from Vector_operations_on_data import vector_mean;\n",
    "from gradient_descent import gradient_step;\n",
    "\n",
    "def least_squares_fit(xs:List[Vector],\n",
    "                      ys: List[Vector],\n",
    "                      learning_rate: float = 0.001,\n",
    "                      num_steps: int = 1000,\n",
    "                      batch_size: int = 1) -> Vector:\n",
    "    \"\"\"Find beta that minimizes the sum of squared errors\n",
    "    assuming the model y = dot(x,beta)\"\"\"\n",
    "    \n",
    "    #Start with a random guess\n",
    "    guess = [random.random() for _ in xs[0]]\n",
    "    \n",
    "    for _ in tqdm.trange(num_steps, desc=\"least squares fit\"):\n",
    "        for start in range(0, len(xs), batch_size):\n",
    "            batch_xs = xs[start:start+batch_size]\n",
    "            batch_ys = ys[start:start+batch_size]\n",
    "            \n",
    "            gradient =vector_mean([sqerror_gradient(x,y,guess)\n",
    "                                  for x,y in zip(batch_xs, batch_ys)])\n",
    "\n",
    "            guess = gradient_step(guess, gradient,-learning_rate)\n",
    "            \n",
    "    return guess\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "from Statistics import daily_minutes_good;\n",
    "\n",
    "inputs: List[List[float]] = [[1.,49,4,0],[1,41,9,0],[1,40,8,0],[1,25,6,0],[1,21,1,0],[1,21,0,0],[1,19,3,0],[1,19,0,0],[1,18,9,0],[1,18,8,0],[1,16,4,0],[1,15,3,0],[1,15,0,0],[1,15,2,0],[1,15,7,0],[1,14,0,0],[1,14,1,0],[1,13,1,0],[1,13,7,0],[1,13,4,0],[1,13,2,0],[1,12,5,0],[1,12,0,0],[1,11,9,0],[1,10,9,0],[1,10,1,0],[1,10,1,0],[1,10,7,0],[1,10,9,0],[1,10,1,0],[1,10,6,0],[1,10,6,0],[1,10,8,0],[1,10,10,0],[1,10,6,0],[1,10,0,0],[1,10,5,0],[1,10,3,0],[1,10,4,0],[1,9,9,0],[1,9,9,0],[1,9,0,0],[1,9,0,0],[1,9,6,0],[1,9,10,0],[1,9,8,0],[1,9,5,0],[1,9,2,0],[1,9,9,0],[1,9,10,0],[1,9,7,0],[1,9,2,0],[1,9,0,0],[1,9,4,0],[1,9,6,0],[1,9,4,0],[1,9,7,0],[1,8,3,0],[1,8,2,0],[1,8,4,0],[1,8,9,0],[1,8,2,0],[1,8,3,0],[1,8,5,0],[1,8,8,0],[1,8,0,0],[1,8,9,0],[1,8,10,0],[1,8,5,0],[1,8,5,0],[1,7,5,0],[1,7,5,0],[1,7,0,0],[1,7,2,0],[1,7,8,0],[1,7,10,0],[1,7,5,0],[1,7,3,0],[1,7,3,0],[1,7,6,0],[1,7,7,0],[1,7,7,0],[1,7,9,0],[1,7,3,0],[1,7,8,0],[1,6,4,0],[1,6,6,0],[1,6,4,0],[1,6,9,0],[1,6,0,0],[1,6,1,0],[1,6,4,0],[1,6,1,0],[1,6,0,0],[1,6,7,0],[1,6,0,0],[1,6,8,0],[1,6,4,0],[1,6,2,1],[1,6,1,1],[1,6,3,1],[1,6,6,1],[1,6,4,1],[1,6,4,1],[1,6,1,1],[1,6,3,1],[1,6,4,1],[1,5,1,1],[1,5,9,1],[1,5,4,1],[1,5,6,1],[1,5,4,1],[1,5,4,1],[1,5,10,1],[1,5,5,1],[1,5,2,1],[1,5,4,1],[1,5,4,1],[1,5,9,1],[1,5,3,1],[1,5,10,1],[1,5,2,1],[1,5,2,1],[1,5,9,1],[1,4,8,1],[1,4,6,1],[1,4,0,1],[1,4,10,1],[1,4,5,1],[1,4,10,1],[1,4,9,1],[1,4,1,1],[1,4,4,1],[1,4,4,1],[1,4,0,1],[1,4,3,1],[1,4,1,1],[1,4,3,1],[1,4,2,1],[1,4,4,1],[1,4,4,1],[1,4,8,1],[1,4,2,1],[1,4,4,1],[1,3,2,1],[1,3,6,1],[1,3,4,1],[1,3,7,1],[1,3,4,1],[1,3,1,1],[1,3,10,1],[1,3,3,1],[1,3,4,1],[1,3,7,1],[1,3,5,1],[1,3,6,1],[1,3,1,1],[1,3,6,1],[1,3,10,1],[1,3,2,1],[1,3,4,1],[1,3,2,1],[1,3,1,1],[1,3,5,1],[1,2,4,1],[1,2,2,1],[1,2,8,1],[1,2,3,1],[1,2,1,1],[1,2,9,1],[1,2,10,1],[1,2,9,1],[1,2,4,1],[1,2,5,1],[1,2,0,1],[1,2,9,1],[1,2,9,1],[1,2,0,1],[1,2,1,1],[1,2,1,1],[1,2,4,1],[1,1,0,1],[1,1,2,1],[1,1,2,1],[1,1,5,1],[1,1,3,1],[1,1,10,1],[1,1,6,1],[1,1,0,1],[1,1,8,1],[1,1,6,1],[1,1,4,1],[1,1,9,1],[1,1,9,1],[1,1,4,1],[1,1,2,1],[1,1,9,1],[1,1,0,1],[1,1,8,1],[1,1,6,1],[1,1,1,1],[1,1,1,1],[1,1,5,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|█████████████████████████████████████████████████████████| 5000/5000 [00:03<00:00, 1381.01it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "####################################################################################################\n",
    "#########################          Evaluate beta on the previously used data  ######################\n",
    "####################################################################################################\n",
    "\"\"\"\n",
    "\n",
    "# Apply on the data\n",
    "random.seed(0)\n",
    "learning_rate =0.001\n",
    "\n",
    "beta = least_squares_fit(inputs,daily_minutes_good, learning_rate, 5000,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30.514795945185586, 0.9748274277323267, -1.8506912934343662, 0.91407780744768]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6799849346187969\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "####################################################################################################\n",
    "#########################                  Compute R squared                  ######################\n",
    "####################################################################################################\n",
    "\"\"\"\n",
    "\n",
    "from linear_regression import total_sum_of_squares;\n",
    "def multiple_r_squared(xs: List[Vector], ys: Vector, beta: Vector) -> float:\n",
    "    sum_of_squared_errors = sum(squared_error(x,y,beta)\n",
    "                               for x,y in zip(xs,ys))\n",
    "    return 1.0 - sum_of_squared_errors/total_sum_of_squares(ys)\n",
    "\n",
    "print(multiple_r_squared(inputs,daily_minutes_good,beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute a statistic on data using bootstrapping\n",
    "# Size of the sample for bootstrapping is same as len(data) but with replacement\n",
    "\n",
    "from typing import TypeVar, List, Callable\n",
    "\n",
    "X = TypeVar('X') # Generic type for data\n",
    "Stat = TypeVar('Stat') # Generic type for statistic\n",
    "\n",
    "def bootstrap_sample(data: List[X]) -> List[X]:\n",
    "    \"\"\"Randomly samples len(data) elements with replacement\"\"\"\n",
    "    return [random.choice(data) for _ in data]\n",
    "\n",
    "def bootstrap_statistic(data: List[X],\n",
    "                       stats_fn: Callable[[List[X]], Stat],\n",
    "                       num_samples: int) -> List[Stat]:\n",
    "    \"\"\"Evaluates stats_fn on num_samples bootstrap samples from data\"\"\"\n",
    "    return [stats_fn(bootstrap_sample(data)) for _ in range(num_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medians_close = [100.08980118353116, 100.10318562796138, 100.04869930383559, 100.08338203945503, 100.06751074062068, 100.10318562796138, 100.07565101416489, 100.07565101416489, 100.00794064252058, 100.13014734041147, 100.04059992494805, 100.08980118353116, 100.06751074062068, 100.01127472136861, 100.07565101416489, 100.04744091132842, 100.05126724609055, 100.09628686158311, 100.15665938898962, 100.10318562796138, 100.07969501074561, 100.20528339985441, 100.10318562796138, 100.08761706417543, 100.08338203945503, 100.06751074062068, 100.04744091132842, 100.07969501074561, 100.1127831050407, 100.04869930383559, 100.08980118353116, 100.08761706417543, 100.1127831050407, 100.11836899667533, 100.1108869734438, 100.1127831050407, 100.04059992494805, 100.08980118353116, 100.13014734041147, 100.13014734041147, 100.11836899667533, 100.09628686158311, 100.10318562796138, 100.07565101416489, 100.05126724609055, 100.04744091132842, 100.1127831050407, 100.10318562796138, 100.1127831050407, 100.13014734041147, 100.04028360697032, 100.1127831050407, 100.08761706417543, 100.07565101416489, 100.08980118353116, 100.04744091132842, 100.08761706417543, 100.08338203945503, 100.1108869734438, 100.1108869734438, 100.10318562796138, 100.05126724609055, 100.07565101416489, 100.09628686158311, 100.13014734041147, 100.11836899667533, 100.08761706417543, 100.13014734041147, 100.10318562796138, 100.07969501074561, 100.1127831050407, 100.08761706417543, 100.07969501074561, 100.08761706417543, 100.09628686158311, 100.08980118353116, 100.07565101416489, 100.08761706417543, 100.09628686158311, 100.04059992494805, 100.08761706417543, 100.09628686158311, 100.07565101416489, 100.09628686158311, 99.99357786646533, 100.04059992494805, 100.11277317986861, 100.16815320123185, 100.06751074062068, 100.08338203945503, 100.13014734041147, 100.10318562796138, 100.09628686158311, 100.09628686158311, 100.1108869734438, 100.10318562796138, 100.04869930383559, 100.07969501074561, 100.01127472136861, 100.11277317986861]\n",
      "\n",
      "medians_far = [200.0456964935684, 100.23148922079085, 200.15768657212232, 0.9882351487225011, 0.9882351487225011, 200.15768657212232, 200.19230954124467, 200.00152422185673, 0.9610312802396112, 200.17481948445143, 200.01243631882932, 0.9100160146990397, 0.9805166506472687, 100.23148922079085, 0.9610312802396112, 0.8159130965336595, 0.9369691586445807, 200.01243631882932, 200.25068733928512, 0.9805166506472687, 100.23148922079085, 0.9805166506472687, 200.24013040782634, 200.17481948445143, 0.9882351487225011, 0.6762017842993783, 200.00152422185673, 0.9610312802396112, 200.17481948445143, 0.9882351487225011, 200.01243631882932, 0.9100160146990397, 200.17481948445143, 0.9665489030431832, 0.9369691586445807, 0.8159130965336595, 200.19230954124467, 0.9610312802396112, 0.8383265651934163, 200.00152422185673, 0.9882351487225011, 200.01243631882932, 0.9369691586445807, 0.9665489030431832, 200.01243631882932, 0.9805166506472687, 200.0467796859568, 200.0467796859568, 0.9610312802396112, 0.8159130965336595, 0.9369691586445807, 0.9882351487225011, 100.23148922079085, 200.0467796859568, 200.15768657212232, 200.17481948445143, 200.0456964935684, 200.00152422185673, 200.25922692344722, 200.25093266482213, 200.0456964935684, 0.9610312802396112, 200.0467796859568, 0.9665489030431832, 0.9369691586445807, 200.01243631882932, 0.9805166506472687, 200.00152422185673, 0.9100160146990397, 200.24013040782634, 200.23941596018597, 0.7315983062253606, 200.17481948445143, 200.01243631882932, 0.9665489030431832, 0.9665489030431832, 0.9100160146990397, 0.9610312802396112, 0.9665489030431832, 0.9882351487225011, 200.0467796859568, 0.9805166506472687, 200.25093266482213, 200.25068733928512, 200.0456964935684, 200.15768657212232, 200.24013040782634, 0.9610312802396112, 0.9184820619953314, 0.9805166506472687, 200.15768657212232, 0.8383265651934163, 200.0467796859568, 0.7315983062253606, 200.01243631882932, 0.8383265651934163, 0.9184820619953314, 100.23148922079085, 0.9184820619953314, 100.23148922079085]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Data1: Sample 101 points all very close to 100\n",
    "close_to_100 = [99.5 + random.random() for _ in range(101)]\n",
    "\n",
    "# Data2: Sample 101 points, 50 of them near 0 and 50 of them near 100\n",
    "far_from_100 = ([99.5 + random.random()] +\n",
    "                [random.random() for _ in range(50)] +\n",
    "                [200 + random.random() for _ in range(50)])\n",
    "\n",
    "# Compare median value of Data1 and Data2\n",
    "from Statistics import median, standard_deviation, mean;\n",
    "\n",
    "medians_close = bootstrap_statistic(close_to_100, median, 100)\n",
    "medians_far = bootstrap_statistic(far_from_100, median, 100)\n",
    "print(f\"medians_close = {medians_close}\\n\")\n",
    "\n",
    "print(f\"medians_far = {medians_far}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std_medians_close = 0.03297014219316836\n",
      "std_medians_far = 96.96111685099788\n"
     ]
    }
   ],
   "source": [
    "std_close = standard_deviation(medians_close)\n",
    "std_far = standard_deviation(medians_far)\n",
    "\n",
    "print(f\"std_medians_close = {std_close}\")\n",
    "print(f\"std_medians_far = {std_far}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_medians_close = 100.0880427790533\n",
      "mean_medians_far = 96.51855033715518\n"
     ]
    }
   ],
   "source": [
    "mean_close = mean(medians_close)\n",
    "mean_far = mean(medians_far)\n",
    "\n",
    "print(f\"mean_medians_close = {mean_close}\")\n",
    "print(f\"mean_medians_far = {mean_far}\")"
   ]
  },
  
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap sample [32.386076915787775, 0.880783952413711, -2.152698001942056, 0.7686478954139024]\n"
     ]
    },
   
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|█████████████████████████████████████████████████████████| 5000/5000 [00:02<00:00, 1946.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap sample [31.53641131903816, 0.87226791894672, -1.7612035547571374, -0.6452256585956581]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|█████████████████████████████████████████████████████████| 5000/5000 [00:02<00:00, 1833.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap sample [33.07226931454811, 0.8676459599582815, -2.0873998003646945, 0.0013180275339494325]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|█████████████████████████████████████████████████████████| 5000/5000 [00:02<00:00, 1862.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap sample [29.641075267098337, 1.138906963708923, -2.0625168763982655, 1.7772607056047018]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|█████████████████████████████████████████████████████████| 5000/5000 [00:02<00:00, 1942.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap sample [27.39240711398243, 1.192569689813304, -1.7973874477434921, 2.117197108256202]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|█████████████████████████████████████████████████████████| 5000/5000 [00:02<00:00, 1875.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap sample [30.069916703089255, 0.9535400247776886, -2.1082594825855527, 2.6448657270762825]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|█████████████████████████████████████████████████████████| 5000/5000 [00:02<00:00, 1881.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap sample [31.044085471554304, 1.0895393593743032, -2.05041409700431, 1.859577540165332]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|█████████████████████████████████████████████████████████| 5000/5000 [00:02<00:00, 1882.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap sample [30.19075237210024, 0.996549674270733, -1.7435441681997834, 1.4213591952347786]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|█████████████████████████████████████████████████████████| 5000/5000 [00:02<00:00, 2022.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap sample [28.554313142878275, 1.1435642451667354, -1.92121735306766, 1.8722055850192119]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|█████████████████████████████████████████████████████████| 5000/5000 [00:02<00:00, 2008.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap sample [31.052840485881827, 0.883998908011057, -1.7460996464749026, -0.16192767571997296]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|█████████████████████████████████████████████████████████| 5000/5000 [00:02<00:00, 1976.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap sample [29.18426426972927, 0.9766551010420155, -1.6940391437924456, 2.0497826784058195]\n"
     ]
    },
   
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|█████████████████████████████████████████████████████████| 5000/5000 [00:03<00:00, 1575.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap sample [28.771592979638456, 0.9550883505010757, -1.80861870267413, 2.1999238056053736]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|█████████████████████████████████████████████████████████| 5000/5000 [00:02<00:00, 1694.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap sample [30.811715650751754, 1.0530261901522913, -1.8849463610522954, -0.3865837917019028]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|█████████████████████████████████████████████████████████| 5000/5000 [00:02<00:00, 1940.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap sample [30.747945746661284, 0.978606091699977, -1.8038241416727663, 1.5649085243043792]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|█████████████████████████████████████████████████████████| 5000/5000 [00:02<00:00, 1959.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap sample [30.800679606704893, 0.9818253931069941, -1.8431667585677023, 0.39381413805322757]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|█████████████████████████████████████████████████████████| 5000/5000 [00:02<00:00, 1963.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap sample [31.424960397875374, 0.8842160009639013, -1.9013686791257474, -0.5453791101228972]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|█████████████████████████████████████████████████████████| 5000/5000 [00:02<00:00, 1791.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap sample [32.7593672394827, 0.9666158590225832, -2.0986882771764206, -0.6728819259363616]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|█████████████████████████████████████████████████████████| 5000/5000 [00:03<00:00, 1655.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap sample [29.613651238998198, 0.9969155594663676, -1.6024911795390704, 0.47165300251194375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|█████████████████████████████████████████████████████████| 5000/5000 [00:02<00:00, 1690.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap sample [29.45970382920406, 1.0327004565587354, -1.819141947074232, 2.128371473431831]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|█████████████████████████████████████████████████████████| 5000/5000 [00:02<00:00, 1780.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap sample [31.55328363376976, 0.9061913363333978, -1.8305875558918787, 0.6968092702452656]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|█████████████████████████████████████████████████████████| 5000/5000 [00:02<00:00, 1966.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap sample [29.713392910055305, 0.9490157111129571, -1.8480807184615102, 1.7176862904550494]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|█████████████████████████████████████████████████████████| 5000/5000 [00:02<00:00, 1962.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap sample [31.508111968119252, 0.9137823491466879, -1.7591126353832334, 0.8285430482289633]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|█████████████████████████████████████████████████████████| 5000/5000 [00:02<00:00, 1969.88it/s]\n"
     ]
    },
    
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|█████████████████████████████████████████████████████████| 5000/5000 [00:03<00:00, 1560.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap sample [29.994732018547484, 1.008497696129308, -1.782304798192897, 1.3246796826262317]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|█████████████████████████████████████████████████████████| 5000/5000 [00:03<00:00, 1612.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap sample [30.6328522053077, 1.0083508877714147, -1.7719205944551237, 1.2146160285485168]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "####################################################################################################\n",
    "#########################      Estimate sample beta using bootstrapping        ######################\n",
    "####################################################################################################\n",
    "\"\"\"  \n",
    "from typing import Tuple\n",
    "import datetime\n",
    "\n",
    "def estimate_sample_beta(pairs: List[Tuple[Vector, float]]) -> Vector:\n",
    "    x_sample = [x for x,_ in pairs]\n",
    "    y_sample = [y for _, y in pairs]\n",
    "    \n",
    "    beta = least_squares_fit(x_sample, y_sample, learning_rate, 5000, 25)\n",
    "    print(\"Bootstrap sample\", beta)\n",
    "    return beta\n",
    "\n",
    "bootstrap_betas = bootstrap_statistic(list(zip(inputs, daily_minutes_good)),\n",
    "                                     estimate_sample_beta, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bootstrap_betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2701124117467086, 0.08840138336203103, 0.1507875750383838, 1.0442805115408522]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "####################################################################################################\n",
    "#########################   Compute statistics on bootstrapped coefficients(betas)   ###############\n",
    "####################################################################################################\n",
    "\"\"\"    \n",
    "bootstrap_standard_errors = [\n",
    "    standard_deviation([beta[i] for beta in bootstrap_betas]) \n",
    "    for i in range(4)]\n",
    "\n",
    "print(bootstrap_standard_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37480976619644935"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Probability import normal_cdf;\n",
    "\n",
    "def p_value(beta_hat_j: float, sigma_hat_j: float) -> float:\n",
    "    if beta_hat_j > 0:\n",
    "        #if the coefficient is positive, we need to compute\n",
    "        #twice the probability of seeing an even larger value\"\"\"\n",
    "        return 2*(1-normal_cdf(beta_hat_j/sigma_hat_j))\n",
    "        #\"\"\"Otherwise twice the probability of a smaller value\"\"\"\n",
    "    else:\n",
    "        return 2*(normal_cdf(beta_hat_j/sigma_hat_j))\n",
    "    \n",
    "p_value(0.923,1.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Regularization\n",
    "# alpha is a coefficient which decides how harsh the penalty is\n",
    "\n",
    "#L2 norm\n",
    "def ridge_penalty(beta: Vector,\n",
    "                 alpha: float) -> float:\n",
    "    return alpha * dot(beta[1:], beta[1:])\n",
    "\n",
    "def squared_error_ridge(x: Vector,\n",
    "                       y: float,\n",
    "                       alpha: float) -> float:\n",
    "    \"\"\"estimate error plus ridge penalty\"\"\"\n",
    "    return error(x,y,beta)**2 + ridge_penalty(beta, alpha)\n",
    "\n",
    "from Vector_operations_on_data import add\n",
    "def ridge_penality_gradient(beta: Vector, alpha: float) -> float:\n",
    "    \"\"\"gradient of just ridge penality\"\"\"\n",
    "    return [0.] + [2*alpha*beta_j for beta_j in beta[1:]]\n",
    "\n",
    "def sqerror_ridge_gradient(x: Vector,\n",
    "                          y: float, beta: Vector,\n",
    "                          alpha: float) -> Vector:\n",
    "    \"\"\"gradient corresponding to the i-th squared error term\n",
    "    including ridge penalty\"\"\"\n",
    "    return add(sqerror_gradient(x,y,beta), \n",
    "               ridge_penality_gradient(beta, alpha))\n",
    "\n",
    "def least_squares_fit(xs: List[Vector],\n",
    "                     ys: Vector,\n",
    "                     alpha: float,\n",
    "                     learning_rate: float = 0.001,\n",
    "                     num_steps: int = 1000,\n",
    "                     batch_size: int = 1) -> Vector:\n",
    "    \"\"\"Finds beta that minimizes the sum of squared errors\n",
    "    assuming the model dot(x, beta)\"\"\"\n",
    "    # start with random guess\n",
    "    guess = [random.random() for _ in xs[0]]\n",
    "    \n",
    "    for _ in tqdm.trange(num_steps, desc = \"least squares fit\"):\n",
    "        for start in range(0,len(xs), batch_size):\n",
    "            batch_xs = xs[start:start+batch_size]\n",
    "            batch_ys = ys[start:start+batch_size]\n",
    "            \n",
    "            gradient = vector_mean([sqerror_ridge_gradient(x,y,guess,alpha)\n",
    "                                  for x,y in zip(batch_xs, batch_ys)])\n",
    "            \n",
    "            guess = gradient_step(guess, gradient, -learning_rate)\n",
    "    return guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|██████████████████████████████████████████████████████████| 5000/5000 [00:05<00:00, 860.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[30.514795945185586, 0.9748274277323267, -1.8506912934343662, 0.91407780744768]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(0)\n",
    "beta_0 = least_squares_fit(inputs, daily_minutes_good, 0.0,\n",
    "                          learning_rate, 5000,25)\n",
    "beta_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "least squares fit: 100%|██████████████████████████████████████████████████████████| 5000/5000 [00:05<00:00, 848.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[30.80152599845916, 0.9507225777158704, -1.833142990416332, 0.5384447644638315]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_1 = least_squares_fit(inputs, daily_minutes_good, 0.1,\n",
    "                          learning_rate, 5000,25)\n",
    "beta_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_penlty(beta,alpha): #L1\n",
    "    return alpha*sum(abs(beta_i) for beta_i in beta[1:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
