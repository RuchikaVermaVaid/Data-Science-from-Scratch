{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5.0, 3.0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define least square fit function\n",
    "\n",
    "def predict (alpha: float, beta: float, x_i: float) -> float:\n",
    "    return beta*x_i+alpha\n",
    "\n",
    "def error(alpha: float, beta: float, x_i: float, y_i: float) -> float:\n",
    "    # The error from predicting beta*x_i+alpha and y_i\n",
    "    return predict(alpha, beta, x_i) - y_i\n",
    "\n",
    "from Vector_operations_on_data import Vector\n",
    "def sum_of_sqerrors (alpha: float, beta: float, x: Vector, y: Vector) -> float:\n",
    "    return sum(error(alpha, beta, x_i, y_i)**2 \n",
    "               for x_i, y_i in zip(x,y))\n",
    "\n",
    "from typing import Tuple\n",
    "from Statistics import correlation, standard_deviation, mean\n",
    "\n",
    "def least_squares_fit(x: Vector, y: Vector) -> Tuple[float,float]:\n",
    "    \"\"\"Given two vectors x and y,\n",
    "    find the least-squares value of alpha and beta\"\"\"\n",
    "    beta = correlation(x,y)*standard_deviation(y)/standard_deviation(x)\n",
    "    alpha = mean(y) - beta*mean(x)\n",
    "    #print(alpha, beta)\n",
    "    return alpha, beta\n",
    "\n",
    "x = [i for i in range(-100, 110, 10)]\n",
    "y = [3 * i - 5 for i in x]\n",
    "\n",
    "least_squares_fit(x,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22.94755241346903, 0.903865945605865)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate alpha and beta on the previously used data\n",
    "from Statistics import num_friends_good, daily_minutes_good\n",
    "alpha, beta = least_squares_fit(num_friends_good, daily_minutes_good)\n",
    "alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3291078377836305\n",
      "This tells how better we fit the model\n",
      "The higher the number, the better our model fits the data\n"
     ]
    }
   ],
   "source": [
    "# Find coefficient of determination or R squared\n",
    "from typing import List\n",
    "def de_mean(xs: List[float]) -> List[float]:\n",
    "    \"\"\"Translate xs by subtracting its mean (so the result has mean 0)\"\"\"\n",
    "    x_bar = mean(xs)\n",
    "    return [x - x_bar for x in xs]\n",
    "\n",
    "def total_sum_of_squares(y: Vector) -> float:\n",
    "    \"\"\"the total squared variation of y_i's from their mean\"\"\"\n",
    "    return sum(v ** 2 for v in de_mean(y))\n",
    "\n",
    "def r_squared(alpha: float, beta: float, x: Vector, y: Vector) -> float:\n",
    "    \"\"\"The fraction of variation in y captured by the model,\n",
    "    which equals 1-the fraction not captured by the model\"\"\"\n",
    "    return 1.0 - (sum_of_sqerrors(alpha, beta, x, y)\n",
    "               /total_sum_of_squares(y))\n",
    "\n",
    "print(r_squared(alpha, beta, num_friends_good, daily_minutes_good))\n",
    "\n",
    "print(\"This tells how better we fit the model\")\n",
    "print(\"The higher the number, the better our model fits the data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 13196.619297: 100%|███████████████████████████████████████████████████████| 10000/10000 [00:15<00:00, 559.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[22.947552155340915, 0.9038659662765034]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solve the above problem using gradient descent\n",
    "\n",
    "import random \n",
    "import tqdm\n",
    "from gradient_descent import gradient_step;\n",
    "\n",
    "num_epochs = 10000\n",
    "random.seed(0)\n",
    "\n",
    "guess = [random.random(), random.random()] # Choose random value to start\n",
    "\n",
    "learning_rate = 0.00001\n",
    "\n",
    "with tqdm.trange(num_epochs) as t:\n",
    "    for _ in t:\n",
    "        alpha, beta = guess # initial guess\n",
    "        \n",
    "        # partial derivative of loss wrt alpha\n",
    "        grad_a = sum(2 * error(alpha, beta, x_i, y_i)\n",
    "                    for x_i, y_i in zip(num_friends_good, daily_minutes_good))\n",
    "        \n",
    "        # partial derivative of loss wrt beta\n",
    "        grad_b = sum(2*error(alpha, beta, x_i, y_i)*x_i\n",
    "                    for x_i, y_i in zip(num_friends_good, daily_minutes_good))\n",
    "        \n",
    "        # computes loss to stick tqdm description\n",
    "        loss = sum_of_sqerrors(alpha, beta,\n",
    "                              num_friends_good, daily_minutes_good)\n",
    "        t.set_description(f\"loss: {loss:3f}\")\n",
    "        \n",
    "        # Finally update the guess\n",
    "        guess = gradient_step(guess, [grad_a, grad_b], -learning_rate)\n",
    "guess"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
